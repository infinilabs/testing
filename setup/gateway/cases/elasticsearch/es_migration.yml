path.data: data
path.logs: log
progress_bar.enabled: true

elasticsearch:
  - name: source
    enabled: true
    endpoint: http://192.168.3.188:9206
  - name: target
    enabled: true
    endpoints:
      - http://192.168.3.188:9206

pipeline:
  - name: source_scroll
    auto_start: true
    processor:
      - es_scroll:
          slice_size: 10
          batch_size: 5000
          indices: "test-10"
          elasticsearch: source
          output_queue: source_index_dump
          partition_size: 20
#          sort_type: "asc"#desc,asc
#          sort_field: "@timestamp"
          scroll_time: "5m"
#          query_string: "service.type:nginx"
          index_rename:
            "*": "test-10-new"
          type_rename:
            "*": "_doc"

  - name: target_indexing
    auto_start: true
    keep_running: true
    processor:
      - bulk_indexing:
          elasticsearch: target
          max_worker_size: 10
          detect_interval: 100
          bulk:
            compress: true
            batch_size_in_mb: 20
            batch_size_in_docs: 5000
            invalid_queue: bulk_indexing_400
          queues:
            type: scroll_docs
          consumer:
            fetch_max_messages: 1000
          when:
            cluster_available: [ "target" ]

disk_queue:
  sync_timeout_in_ms: 10000
  sync_every_records: 10000




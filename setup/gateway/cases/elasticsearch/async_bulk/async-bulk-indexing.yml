env:
  ES_ENDPOINTS: [ "https://localhost:9200/" ]
  ES_USER: admin
  ES_PASS: 45ff432a5428ade77c7b

path.data: data
path.logs: log

entry:
  - name: my_es_entry
    enabled: true
    router: my_router
    max_concurrency: 200000
    network:
      binding: 0.0.0.0:8000

flow:
  - name: async_bulk
    filter:
      - bulk_reshuffle:
          when:
            contains:
              _ctx.request.path: /_bulk
          elasticsearch: prod
          level: node
          partition_size: 2 #extra partition within level
          #shards: [1,3,5,7,9,11,13] #filter shards to ingest for node or shard level
          continue_metadata_missing: true # If true, will continue to execute following processors if cluster info missing (level: node, shard)
          fix_null_id: true
      - elasticsearch:
          elasticsearch: prod  #elasticsearch configure reference name
          max_connection_per_node: 1000 #max tcp connection to upstream, default for all nodes
          max_response_size: -1 #default for all nodes
          balancer: weight
          refresh: # refresh upstream nodes list, need to enable this feature to use elasticsearch nodes auto discovery
            enabled: true
            interval: 60s
          filter:
            roles:
              exclude:
                - master

elastic:
  metadata_refresh:
    enabled: true

router:
  - name: my_router
    default_flow: async_bulk

elasticsearch:
  - name: prod
    enabled: true
    endpoints: $[[env.ES_ENDPOINTS]]
    discovery:
      enabled: true
    metadata_cache_enabled: false # Whether to cache the cluster info in memory cache
    basic_auth:
      username: $[[env.ES_USER]]
      password: $[[env.ES_PASS]]

pipeline:
  - name: bulk_request_ingest
    auto_start: true
    keep_running: true
    retry_delay_in_ms: 1000
    processor:
      - bulk_indexing:
          max_connection_per_node: 1000
          num_of_slices: 2 #runtime slice
          max_worker_size: 200
          idle_timeout_in_seconds: 10
          bulk:
            compress: false
            batch_size_in_mb: 20
            batch_size_in_docs: 5000
            #invalid_queue: "bulk_invalid_requests"
            invalid_queue: ""
            dead_letter_queue: "bulk_dead_requests"
            response_handle:
              bulk_result_message_queue: "bulk_result_messages"
              max_request_body_size: 1024
              max_response_body_size: 1024
              save_success_results: false
              max_error_details_count: 5
              retry_rules:
                default: true
                retry_429: true
                retry_4xx: false
                denied:
                  status: []
                  keyword:
                    - illegal_state_exception
          consumer:
            fetch_max_messages: 8000
            eof_retry_delay_in_ms: 500
            fetch_max_wait_ms: 10000
            fetch_max_bytes: 20971520
            simple_sliced_group: true
          queue_selector:
            labels:
              type: bulk_reshuffle
